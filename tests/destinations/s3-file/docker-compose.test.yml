# timeout: 60
services:
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    networks:
      - test-network
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 3s
      timeout: 5s
      retries: 10
    stop_grace_period: 3s

  minio-init:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 minioadmin minioadmin;
      mc mb myminio/test-bucket --ignore-existing;
      echo 'MinIO bucket created';
      echo 'Keeping minio-init alive...';
      tail -f /dev/null
      "
    networks:
      - test-network

  kafka:
    image: docker.redpanda.com/redpandadata/redpanda:v24.2.4
    command:
      - redpanda
      - start
      - --kafka-addr internal://0.0.0.0:9092
      - --advertise-kafka-addr internal://kafka:9092
      - --mode dev-container
      - --smp 1
    healthcheck:
      test: ["CMD-SHELL", "rpk cluster health | grep -E 'Healthy:.+true' || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      - test-network
    stop_grace_period: 3s

  s3-file-dest:
    build:
      context: ../../../python/destinations/s3-file
      dockerfile: Dockerfile
    environment:
      - Quix__Broker__Address=kafka:9092
      - Quix__Consumer__Group=s3-file-dest-test
      - Quix__Deployment__Id=test-s3-file-dest
      - input=test-s3-input
      - S3_BUCKET=test-bucket
      - S3_BUCKET_DIRECTORY=test_data
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_REGION_NAME=us-east-1
      - AWS_ENDPOINT_URL_S3=http://minio:9000
      - FILE_FORMAT=json
    networks:
      - test-network
    depends_on:
      minio:
        condition: service_healthy
      kafka:
        condition: service_healthy
      minio-init:
        condition: service_started
    stop_grace_period: 3s

  test-runner:
    build:
      context: ../../framework
      dockerfile: Dockerfile
    environment:
      - Quix__Broker__Address=kafka:9092
      - TEST_INPUT_TOPIC=test-s3-input
      - TEST_MESSAGE_COUNT=3
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - S3_BUCKET=test-bucket
      - S3_PREFIX=test_data
    command: >
      sh -c "
        echo 'Installing boto3 for S3 access...' &&
        pip install boto3 > /dev/null 2>&1 &&
        echo 'Producing test messages to Kafka...' &&
        python /tests/produce_test_data.py &&
        echo 'Waiting for s3-file-dest to process messages...' &&
        sleep 15 &&
        echo 'Verifying data in S3...' &&
        python /tests/verify_output.py
      "
    volumes:
      - ./produce_test_data.py:/tests/produce_test_data.py:ro
      - ./verify_output.py:/tests/verify_output.py:ro
    working_dir: /
    networks:
      - test-network
    depends_on:
      minio:
        condition: service_healthy
      kafka:
        condition: service_healthy
      s3-file-dest:
        condition: service_started
    stop_grace_period: 3s

networks:
  test-network:
    driver: bridge
