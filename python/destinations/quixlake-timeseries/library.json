{
    "libraryItemId": "quixlake-timeseries-destination",
    "name": "quix-ts-datalake-sink",
    "language": "Python",
    "tags": {
        "Pipeline Stage": ["Destination"],
        "Type": ["Connectors"],
        "Category": ["File Store"]
    },
    "shortDescription": "Consume data from a Kafka topic and write it to an AWS S3 bucket path.",
    "DefaultFile": "main.py",
    "EntryPoint": "dockerfile",
    "RunEntryPoint": "main.py",
    "IconFile": "icon.png",
    "Variables": [
        {
            "Name": "input",
            "Type": "EnvironmentVariable",
            "InputType": "InputTopic",
            "Description": "Name of the Kafka input topic to consume from",
            "DefaultValue": "tsbs_data_transformed",
            "Required": true
        },
        {
            "Name": "S3_PREFIX",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "S3 prefix/path for data files",
            "DefaultValue": "data-lake/time-series"
        },
        {
            "Name": "TABLE_NAME",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "Table name for data organization and registration, else defaults to topic name",
            "DefaultValue": "sensordata"
        },
        {
            "Name": "HIVE_COLUMNS",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "Comma-separated list of columns for Hive partitioning. Include year/month/day/hour to extract from TIMESTAMP_COLUMN (e.g., location,year,month,day,sensor_type)",
            "DefaultValue": "region,datacenter,hostname"
        },
        {
            "Name": "TIMESTAMP_COLUMN",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "Column containing timestamp values to extract year/month/day/hour from",
            "DefaultValue": "ts_ms"
        },
        {
            "Name": "CATALOG_URL",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "REST Catalog URL for optional table registration (leave empty to skip)"
        },
        {
            "Name": "COMMIT_INTERVAL",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "Kafka commit interval in seconds",
            "DefaultValue": "30"
        },
        {
            "Name": "CONSUMER_GROUP",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "Kafka consumer group name",
            "DefaultValue": "s3_direct_sink_v1.0"
        },
        {
            "Name": "AUTO_OFFSET_RESET",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "Where to start consuming if no offset exists",
            "DefaultValue": "earliest"
        },
        {
            "Name": "AWS_ACCESS_KEY_ID",
            "Type": "EnvironmentVariable",
            "InputType": "Secret",
            "Description": "AWS Access Key ID for S3 access",
            "DefaultValue": ""
        },
        {
            "Name": "AWS_SECRET_ACCESS_KEY",
            "Type": "EnvironmentVariable",
            "InputType": "Secret",
            "Description": "AWS Secret Access Key for S3 access"
        },
        {
            "Name": "AWS_REGION",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "AWS region for S3 bucket",
            "DefaultValue": "us-east-1"
        },
        {
            "Name": "AWS_ENDPOINT_URL",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "S3 endpoint url (for non-AWS endpoints)"
        },
        {
            "Name": "LOGLEVEL",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "set application logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)",
            "DefaultValue": "INFO"
        },
        {
            "Name": "MAX_WRITE_WORKERS",
            "Type": "EnvironmentVariable",
            "InputType": "FreeText",
            "Description": "How many files can be written in parallel to storage at once (based on partitioning + batch size)",
            "DefaultValue": "10"
        }
    ],
    "DeploySettings": {
        "DeploymentType": "Service",
        "CpuMillicores": 200,
        "MemoryInMb": 500,
        "Replicas": 1,
        "PublicAccess": false,
        "ValidateConnection": false
    }
}
